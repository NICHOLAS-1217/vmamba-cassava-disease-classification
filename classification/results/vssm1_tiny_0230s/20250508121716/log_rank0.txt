[2025-05-08 12:17:17 vssm1_tiny_0230s] (main.py 485): INFO Full config saved to results/vssm1_tiny_0230s/20250508121716/config.json
[2025-05-08 12:17:17 vssm1_tiny_0230s] (main.py 488): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /home/nicho/documents/cassava
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 8
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: true
FUSED_LAYERNORM: false
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  MMCKPT: false
  NAME: vssm1_tiny_0230s
  NUM_CLASSES: 5
  PRETRAINED: models/vssm1_tiny_0230s_ckpt_epoch_264.pth
  RESUME: out/vssm1_tiny_0230s/20250507200359/best_model.pth
  TYPE: vssm
  VSSM:
    DEPTHS:
    - 2
    - 2
    - 8
    - 2
    DOWNSAMPLE: v3
    EMBED_DIM: 96
    GMLP: false
    IN_CHANS: 3
    MLP_ACT_LAYER: gelu
    MLP_DROP_RATE: 0.0
    MLP_RATIO: 4.0
    NORM_LAYER: ln2d
    PATCHEMBED: v2
    PATCH_NORM: true
    PATCH_SIZE: 4
    POSEMBED: false
    SSM_ACT_LAYER: silu
    SSM_CONV: 3
    SSM_CONV_BIAS: false
    SSM_DROP_RATE: 0.0
    SSM_DT_RANK: auto
    SSM_D_STATE: 1
    SSM_FORWARDTYPE: v05_noz
    SSM_INIT: v0
    SSM_RANK_RATIO: 2.0
    SSM_RATIO: 1.0
OUTPUT: results/vssm1_tiny_0230s/20250508121716
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: '20250508121716'
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 0.000125
  CLIP_GRAD: 5.0
  EPOCHS: 100
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 10
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.25e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 1.25e-07
  WEIGHT_DECAY: 0.05
TRAINCOST_MODE: false

[2025-05-08 12:17:17 vssm1_tiny_0230s] (main.py 489): INFO {"cfg": "configs/vssm/vmambav2v_tiny_224.yaml", "opts": null, "batch_size": null, "data_path": "/home/nicho/documents/cassava", "zip": false, "cache_mode": "part", "pretrained": null, "resume": "out/vssm1_tiny_0230s/20250507200359/best_model.pth", "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "output": "results/", "tag": "20250508121716", "eval": true, "throughput": false, "fused_layernorm": false, "optim": null, "model_ema": false, "model_ema_decay": 0.9999, "model_ema_force_cpu": false, "memory_limit_rate": -1}
[2025-05-08 12:17:17 vssm1_tiny_0230s] (main.py 143): INFO Creating model:vssm/vssm1_tiny_0230s
[2025-05-08 12:17:17 vssm1_tiny_0230s] (main.py 148): INFO VSSM(
  (patch_embed): Sequential(
    (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): Identity()
    (2): LayerNorm2d((48,), eps=1e-05, elementwise_affine=True)
    (3): Identity()
    (4): GELU(approximate='none')
    (5): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (6): Identity()
    (7): LayerNorm2d((96,), eps=1e-05, elementwise_affine=True)
  )
  (layers): ModuleList(
    (0): Sequential(
      (blocks): Sequential(
        (0): VSSBlock(
          (norm): LayerNorm2d((96,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((96,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=96, out_features=96, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=96, out_features=96, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.0)
          (norm2): LayerNorm2d((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VSSBlock(
          (norm): LayerNorm2d((96,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((96,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=96, out_features=96, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=96, out_features=96, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.015384615398943424)
          (norm2): LayerNorm2d((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): Sequential(
        (0): Identity()
        (1): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (2): Identity()
        (3): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): Sequential(
      (blocks): Sequential(
        (0): VSSBlock(
          (norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=192, out_features=192, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=192, out_features=192, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.03076923079788685)
          (norm2): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VSSBlock(
          (norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=192, out_features=192, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=192, out_features=192, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.04615384712815285)
          (norm2): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): Sequential(
        (0): Identity()
        (1): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (2): Identity()
        (3): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): Sequential(
      (blocks): Sequential(
        (0): VSSBlock(
          (norm): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=384, out_features=384, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=384, out_features=384, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.0615384615957737)
          (norm2): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VSSBlock(
          (norm): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=384, out_features=384, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=384, out_features=384, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.07692307978868484)
          (norm2): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): VSSBlock(
          (norm): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=384, out_features=384, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=384, out_features=384, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.0923076942563057)
          (norm2): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): VSSBlock(
          (norm): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=384, out_features=384, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=384, out_features=384, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.10769230872392654)
          (norm2): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): VSSBlock(
          (norm): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=384, out_features=384, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=384, out_features=384, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.1230769231915474)
          (norm2): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): VSSBlock(
          (norm): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=384, out_features=384, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=384, out_features=384, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.13846154510974884)
          (norm2): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): VSSBlock(
          (norm): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=384, out_features=384, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=384, out_features=384, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.1538461595773697)
          (norm2): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): VSSBlock(
          (norm): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=384, out_features=384, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=384, out_features=384, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.16923077404499054)
          (norm2): LayerNorm2d((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): Sequential(
        (0): Identity()
        (1): Conv2d(384, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (2): Identity()
        (3): LayerNorm2d((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): Sequential(
      (blocks): Sequential(
        (0): VSSBlock(
          (norm): LayerNorm2d((768,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((768,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=768, out_features=768, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=768, out_features=768, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.1846153885126114)
          (norm2): LayerNorm2d((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VSSBlock(
          (norm): LayerNorm2d((768,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((768,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=768, out_features=768, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=768, out_features=768, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.20000000298023224)
          (norm2): LayerNorm2d((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): Identity()
    )
  )
  (classifier): Sequential(
    (norm): LayerNorm2d((768,), eps=1e-05, elementwise_affine=True)
    (permute): Identity()
    (avgpool): AdaptiveAvgPool2d(output_size=1)
    (flatten): Flatten(start_dim=1, end_dim=-1)
    (head): Linear(in_features=768, out_features=1000, bias=True)
  )
)
[2025-05-08 12:17:17 vssm1_tiny_0230s] (main.py 150): INFO number of params: 30249064
[2025-05-08 12:17:20 vssm1_tiny_0230s] (main.py 152): INFO number of GFLOPs: 4.905609984
[2025-05-08 12:17:20 vssm1_tiny_0230s] (optimizer.py 18): INFO ==============> building optimizer adamw....................
[2025-05-08 12:17:20 vssm1_tiny_0230s] (optimizer.py 36): INFO No weight decay list: ['patch_embed.0.bias', 'patch_embed.2.weight', 'patch_embed.2.bias', 'patch_embed.5.bias', 'patch_embed.7.weight', 'patch_embed.7.bias', 'layers.0.blocks.0.norm.weight', 'layers.0.blocks.0.norm.bias', 'layers.0.blocks.0.op.Ds', 'layers.0.blocks.0.op.out_norm.weight', 'layers.0.blocks.0.op.out_norm.bias', 'layers.0.blocks.0.norm2.weight', 'layers.0.blocks.0.norm2.bias', 'layers.0.blocks.0.mlp.fc1.bias', 'layers.0.blocks.0.mlp.fc2.bias', 'layers.0.blocks.1.norm.weight', 'layers.0.blocks.1.norm.bias', 'layers.0.blocks.1.op.Ds', 'layers.0.blocks.1.op.out_norm.weight', 'layers.0.blocks.1.op.out_norm.bias', 'layers.0.blocks.1.norm2.weight', 'layers.0.blocks.1.norm2.bias', 'layers.0.blocks.1.mlp.fc1.bias', 'layers.0.blocks.1.mlp.fc2.bias', 'layers.0.downsample.1.bias', 'layers.0.downsample.3.weight', 'layers.0.downsample.3.bias', 'layers.1.blocks.0.norm.weight', 'layers.1.blocks.0.norm.bias', 'layers.1.blocks.0.op.Ds', 'layers.1.blocks.0.op.out_norm.weight', 'layers.1.blocks.0.op.out_norm.bias', 'layers.1.blocks.0.norm2.weight', 'layers.1.blocks.0.norm2.bias', 'layers.1.blocks.0.mlp.fc1.bias', 'layers.1.blocks.0.mlp.fc2.bias', 'layers.1.blocks.1.norm.weight', 'layers.1.blocks.1.norm.bias', 'layers.1.blocks.1.op.Ds', 'layers.1.blocks.1.op.out_norm.weight', 'layers.1.blocks.1.op.out_norm.bias', 'layers.1.blocks.1.norm2.weight', 'layers.1.blocks.1.norm2.bias', 'layers.1.blocks.1.mlp.fc1.bias', 'layers.1.blocks.1.mlp.fc2.bias', 'layers.1.downsample.1.bias', 'layers.1.downsample.3.weight', 'layers.1.downsample.3.bias', 'layers.2.blocks.0.norm.weight', 'layers.2.blocks.0.norm.bias', 'layers.2.blocks.0.op.Ds', 'layers.2.blocks.0.op.out_norm.weight', 'layers.2.blocks.0.op.out_norm.bias', 'layers.2.blocks.0.norm2.weight', 'layers.2.blocks.0.norm2.bias', 'layers.2.blocks.0.mlp.fc1.bias', 'layers.2.blocks.0.mlp.fc2.bias', 'layers.2.blocks.1.norm.weight', 'layers.2.blocks.1.norm.bias', 'layers.2.blocks.1.op.Ds', 'layers.2.blocks.1.op.out_norm.weight', 'layers.2.blocks.1.op.out_norm.bias', 'layers.2.blocks.1.norm2.weight', 'layers.2.blocks.1.norm2.bias', 'layers.2.blocks.1.mlp.fc1.bias', 'layers.2.blocks.1.mlp.fc2.bias', 'layers.2.blocks.2.norm.weight', 'layers.2.blocks.2.norm.bias', 'layers.2.blocks.2.op.Ds', 'layers.2.blocks.2.op.out_norm.weight', 'layers.2.blocks.2.op.out_norm.bias', 'layers.2.blocks.2.norm2.weight', 'layers.2.blocks.2.norm2.bias', 'layers.2.blocks.2.mlp.fc1.bias', 'layers.2.blocks.2.mlp.fc2.bias', 'layers.2.blocks.3.norm.weight', 'layers.2.blocks.3.norm.bias', 'layers.2.blocks.3.op.Ds', 'layers.2.blocks.3.op.out_norm.weight', 'layers.2.blocks.3.op.out_norm.bias', 'layers.2.blocks.3.norm2.weight', 'layers.2.blocks.3.norm2.bias', 'layers.2.blocks.3.mlp.fc1.bias', 'layers.2.blocks.3.mlp.fc2.bias', 'layers.2.blocks.4.norm.weight', 'layers.2.blocks.4.norm.bias', 'layers.2.blocks.4.op.Ds', 'layers.2.blocks.4.op.out_norm.weight', 'layers.2.blocks.4.op.out_norm.bias', 'layers.2.blocks.4.norm2.weight', 'layers.2.blocks.4.norm2.bias', 'layers.2.blocks.4.mlp.fc1.bias', 'layers.2.blocks.4.mlp.fc2.bias', 'layers.2.blocks.5.norm.weight', 'layers.2.blocks.5.norm.bias', 'layers.2.blocks.5.op.Ds', 'layers.2.blocks.5.op.out_norm.weight', 'layers.2.blocks.5.op.out_norm.bias', 'layers.2.blocks.5.norm2.weight', 'layers.2.blocks.5.norm2.bias', 'layers.2.blocks.5.mlp.fc1.bias', 'layers.2.blocks.5.mlp.fc2.bias', 'layers.2.blocks.6.norm.weight', 'layers.2.blocks.6.norm.bias', 'layers.2.blocks.6.op.Ds', 'layers.2.blocks.6.op.out_norm.weight', 'layers.2.blocks.6.op.out_norm.bias', 'layers.2.blocks.6.norm2.weight', 'layers.2.blocks.6.norm2.bias', 'layers.2.blocks.6.mlp.fc1.bias', 'layers.2.blocks.6.mlp.fc2.bias', 'layers.2.blocks.7.norm.weight', 'layers.2.blocks.7.norm.bias', 'layers.2.blocks.7.op.Ds', 'layers.2.blocks.7.op.out_norm.weight', 'layers.2.blocks.7.op.out_norm.bias', 'layers.2.blocks.7.norm2.weight', 'layers.2.blocks.7.norm2.bias', 'layers.2.blocks.7.mlp.fc1.bias', 'layers.2.blocks.7.mlp.fc2.bias', 'layers.2.downsample.1.bias', 'layers.2.downsample.3.weight', 'layers.2.downsample.3.bias', 'layers.3.blocks.0.norm.weight', 'layers.3.blocks.0.norm.bias', 'layers.3.blocks.0.op.Ds', 'layers.3.blocks.0.op.out_norm.weight', 'layers.3.blocks.0.op.out_norm.bias', 'layers.3.blocks.0.norm2.weight', 'layers.3.blocks.0.norm2.bias', 'layers.3.blocks.0.mlp.fc1.bias', 'layers.3.blocks.0.mlp.fc2.bias', 'layers.3.blocks.1.norm.weight', 'layers.3.blocks.1.norm.bias', 'layers.3.blocks.1.op.Ds', 'layers.3.blocks.1.op.out_norm.weight', 'layers.3.blocks.1.op.out_norm.bias', 'layers.3.blocks.1.norm2.weight', 'layers.3.blocks.1.norm2.bias', 'layers.3.blocks.1.mlp.fc1.bias', 'layers.3.blocks.1.mlp.fc2.bias', 'classifier.norm.weight', 'classifier.norm.bias', 'classifier.head.bias']
[2025-05-08 12:17:20 vssm1_tiny_0230s] (main.py 201): INFO no checkpoint found in results/vssm1_tiny_0230s/20250508121716, ignoring auto resume
[2025-05-08 12:17:20 vssm1_tiny_0230s] (utils.py 18): INFO ==============> Resuming form out/vssm1_tiny_0230s/20250507200359/best_model.pth....................
[2025-05-08 12:17:21 vssm1_tiny_0230s] (utils.py 27): INFO resuming model: <All keys matched successfully>
[2025-05-08 12:17:48 vssm1_tiny_0230s] (main.py 391): INFO Test: [0/34]	Time 27.631 (27.631)	Loss 1.1953 (1.1953)	Acc@1 64.062 (64.062)	Acc@5 100.000 (100.000)	Mem 5323MB
[2025-05-08 12:17:51 vssm1_tiny_0230s] (main.py 391): INFO Test: [10/34]	Time 0.299 (2.777)	Loss 0.1823 (0.7160)	Acc@1 97.656 (80.895)	Acc@5 100.000 (100.000)	Mem 5323MB
[2025-05-08 12:17:53 vssm1_tiny_0230s] (main.py 391): INFO Test: [20/34]	Time 0.283 (1.560)	Loss 0.1721 (0.4575)	Acc@1 96.875 (89.025)	Acc@5 100.000 (100.000)	Mem 5323MB
[2025-05-08 12:17:56 vssm1_tiny_0230s] (main.py 391): INFO Test: [30/34]	Time 0.282 (1.148)	Loss 1.0498 (0.4228)	Acc@1 67.188 (89.995)	Acc@5 100.000 (100.000)	Mem 5323MB
[2025-05-08 12:18:00 vssm1_tiny_0230s] (main.py 398): INFO  * Acc@1 88.505 Acc@5 100.000
[2025-05-08 12:18:00 vssm1_tiny_0230s] (main.py 206): INFO Accuracy of the network on the 4280 test images: 88.5%
